# アーキテクチャ設計

このドキュメントでは、ta-backend-mlプロジェクトの全体的なアーキテクチャと設計原則について説明します。

## システム概要

ta-backend-mlは、以下の主要な機能を提供するバックエンドシステムです：

1. 議事録に対する質問応答
2. GitHub活動の分析とナレッジベース化
3. PDF処理と分析
4. Webクローリングとコンテンツ抽出

## 全体アーキテクチャ

システムは以下の主要なコンポーネントから構成されています：

```
+------------------+      +------------------+      +------------------+
|                  |      |                  |      |                  |
|  フロントエンド   +----->+  バックエンド処理  +----->+  外部APIサービス  |
|  (ta-frontend)   |      |  (ta-backend-ml) |      |                  |
|                  |      |                  |      |                  |
+------------------+      +--------+---------+      +------------------+
                                   |
                                   v
                          +------------------+
                          |                  |
                          |  データベース     |
                          |  (MySQL)         |
                          |                  |
                          +------------------+
```

## 処理アーキテクチャ

### 議事録質問応答処理

議事録に対する質問応答は以下のフローで処理されます：

```
質問テキスト
    ↓
関連議事録データの検索
    ↓
LLMによる回答生成
    ↓
ソース情報の添付
    ↓
回答の返却
```

### GitHub活動分析処理

GitHubリポジトリの活動分析は以下のフローで処理されます：

```
リポジトリ情報
    ↓
GitHub APIによるデータ取得
    ↓
コミット・PR・Issue情報の分析
    ↓
開発者活動傾向の抽出
    ↓
LLMによる結果のナレッジベース化
    ↓
結果の保存と返却
```

### PDF処理

PDFドキュメントの処理は以下のフローで行われます：

```
PDFファイル
    ↓
画像形式への変換
    ↓
並列ページ処理
    ↓
Geminiによるテキスト抽出と分析
    ↓
結果の統合と構造化
```

### Webクローリング

Webコンテンツのクローリングと分析は以下のフローで行われます：

```
URL入力
    ↓
ページのクローリング
    ↓
HTML解析とテキスト抽出
    ↓
Markdown変換
    ↓
重要情報の抽出と構造化
```

## データフロー

システム内のデータフローは以下の通りです：

1. フロントエンド → バックエンド：
   - 処理リクエスト
   - 処理パラメータ

2. バックエンド → 外部API：
   - 処理リクエスト（LLM、GitHub API等）

3. 外部API → バックエンド：
   - 処理結果

4. バックエンド → データベース：
   - 処理結果の保存
   - メタデータの記録

5. バックエンド → フロントエンド：
   - 処理完了通知
   - 結果データへの参照

## マイクロサービス構成

ta-backend-mlは、いくつかの緩やかに結合された処理コンポーネントから構成されています：

- **議事録質問応答サービス**: 議事録に対する質問に回答
- **GitHub分析サービス**: リポジトリの活動を分析
- **PDF処理サービス**: PDFファイルを処理・分析
- **Webクローリングサービス**: Webコンテンツを抽出・分析

これらのコンポーネントは個別に開発・テスト・デプロイが可能で、必要に応じて独立して実行できます。

## スケーラビリティ

システムは以下の点でスケーラブルに設計されています：

- **水平スケーリング**: コンテナ化によって複数インスタンスでの並列処理が可能
- **機能モジュール化**: 処理をモジュールに分割し、個別にスケールアップ可能
- **非同期処理**: 長時間かかる処理を非同期で実行し、リソースを効率的に利用

## デプロイアーキテクチャ

```
+------------------+      +------------------+
|                  |      |                  |
|  Docker Compose  +----->+  Kubernetes      |
|  (開発環境)       |      |  (本番環境)       |
|                  |      |                  |
+------------------+      +------------------+
```

- **開発環境**: Docker Composeを使用したローカル開発環境
- **本番環境**: Kubernetesを使用したコンテナオーケストレーション

## 技術スタックの選定理由

### バックエンド言語

- **Python**: AI/ML関連ライブラリが豊富で、データ処理と自然言語処理に適しています。特にLLM関連のライブラリがPythonで最も充実しているため、このプロジェクトに最適です。

### フレームワーク

- **Django**: リクエスト処理とデータモデリングの枠組みを提供します。APIサービスとしての拡張性を考慮して採用しています。

### データベース

- **MySQL**: ta-frontendと共有することによる一貫性の確保と、トランザクション処理の信頼性のために採用しています。
- **Prisma ORM**: タイプセーフなDBアクセスが可能で、スキーマ管理が容易です。フロントエンドと同じORMを使用することで開発効率を高めています。

### AI/ML関連

- **ChatGPT/GPT-3.5 Turbo**: 文脈理解と自然な文章生成能力が高く、質問応答に最適です。
- **Google Vertex AI (Gemini)**: 画像・文書理解と分析に優れています。特にPDF分析に活用しています。

## 将来の展望

今後の技術的な拡張方針は以下の通りです：

1. **より高度なLLM活用**: 最新のモデルとプロンプトエンジニアリングの導入
2. **分散処理の強化**: 大規模データ処理のための分散アーキテクチャ
3. **マルチモーダル処理**: 画像・テキスト・表などを統合的に処理する機能
4. **カスタムモデル**: 特定ドメイン向けの微調整モデルの導入
5. **イベント駆動アーキテクチャ**: メッセージキューなどを活用した疎結合化
